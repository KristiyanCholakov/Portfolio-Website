[
  {
    "id": "portfolio-website",
    "title": "Modern Developer Portfolio",
    "description": "A sleek, interactive, and feature-rich portfolio website built with Next.js and Framer Motion, designed to showcase a developer's skills, projects, and contact information.",
    "longDescription": "This portfolio website features an engaging, interactive UI powered by Framer Motion, with advanced visual effects such as a matrix background, hexagonal patterns, and neural network simulations. It offers a responsive design optimized for all device sizes, a filterable and sortable project grid with dynamic category and technology filters, an interactive tech-stack visualization, and a fully integrated contact form with client-side validation.\n\nBuilt with Next.js (app router) and TypeScript, the project follows industry-standard architecture: reusable UI components, static data for projects and skills, and global utility styles. Styled with Tailwind CSS and enhanced by Three.js and Lucide React icons, it maintains code quality via ESLint and Prettier and is optimized for deployment on Vercel for performance and SEO.",
    "thumbnail": "./projects/portfolio-website.png",
    "technologies": [
      "Next.js",
      "React",
      "Tailwind CSS",
      "Framer Motion",
      "Three.js",
      "TypeScript"
    ],
    "category": "Software Development",
    "featured": true,
    "github": "https://github.com/KristiyanCholakov/Portfolio-Website",
    "demo": "https://kristiyancholakov.com",
    "completed": "2025-04"
  },
  {
    "id": "linkedin-game-agents",
    "title": "LinkedIn Game Agents",
    "description": "A fully automated puzzle-solving agent for LinkedIn’s Queens, Tango, and Zip games combining computer vision and algorithmic reasoning.",
    "longDescription": "This project implements end-to-end agents that autonomously play LinkedIn’s visual logic puzzles: Queens, Tango, and Zip. It uses Selenium to capture game screens, OpenCV and Pillow for image processing, pytesseract for OCR, and scikit-learn for clustering. A modular core dynamically loads each game’s solver, recognizer, and placer components.\n\nEach game employs specialized vision and algorithmic strategies: Queens uses edge filters, Hough transforms, and DBSCAN color clustering to enforce placement constraints; Tango leverages adaptive thresholding, KMeans clustering, and template matching with backtracking to respect sign-based rules; Zip applies adaptive grid detection, dynamic OCR, wall detection, and a Hamiltonian path solver to traverse numbered cells under movement constraints.",
    "thumbnail": "./projects/linkedin-game-agents.png",
    "technologies": [
      "Python",
      "NumPy",
      "OpenCV",
      "scikit-learn"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/LinkedIn-Games-Agents",
    "demo": "https://www.youtube.com/watch?v=XvmLhvoARe0",
    "completed": "2025-04"
  },
  {
    "id": "data-viz-climate-change",
    "title": "The Power of Visualizing Our Planet: From Data to Saving the Environment",
    "description": "An interactive data visualization project illustrating the impact of climate change through animated plots, geospatial maps, and 3D charts.",
    "longDescription": "This project creates engaging and interactive visual narratives to explore the relationship between human activity and environmental impact. It covers human progress versus environmental degradation, the causes of climate change, global consequences, and pathways to a sustainable future through a sequence of dynamic visualizations.\n\nBuilt with Python and Jupyter Notebook, the project features novel custom SVG-based animated plots for sea level rise and Antarctic ice mass; a 4-axis correlation plot showing industrial growth versus environmental decline; custom split bubble world maps for fossil fuel dependency; a 3D segmented water column chart of ocean temperature changes; and a bubble time plot mapping major climate events to their human impacts. Data sourcing and geospatial processing leverage pandas, NumPy, Matplotlib, Seaborn, Plotly, GeoPandas, and GeoPy.",
    "thumbnail": "./projects/data-viz-climate-change.png",
    "technologies": [
      "Python",
      "pandas",
      "NumPy",
      "matplotlib",
      "seaborn",
      "Plotly",
      "Jupyter"
    ],
    "category": "Data Science",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4024-Data-Viz-Climate-Change",
    "demo": "https://youtu.be/64C3F0kX-IU",
    "completed": "2023-12"
  },
  {
    "id": "sentiment-analysis-ablation-study",
    "title": "Sentiment Analysis Ablation Study",
    "description": "An ablation study evaluating various sentiment analysis approaches on the Rotten Tomatoes review dataset, comparing embedding strategies, RNN and transformer architectures, and ensemble techniques.",
    "longDescription": "This group project implements a sentiment classification pipeline using the Rotten Tomatoes movie review dataset. It includes Jupyter Notebooks to compare Word2Vec and GloVe embeddings with extensive preprocessing for out-of-vocabulary mitigation, evaluate RNN-based architectures (with last state, max pooling, average pooling, and attention pooling), fine-tune transformer models, and build an ensemble of multiple models.\n\nKey outcomes include a significant reduction of OOV words through preprocessing, improved accuracy from attention-based and bidirectional RNN variants, custom transformer models achieving around 79% test accuracy, and fine-tuned pretrained models (e.g., ELECTRA) surpassing 90%. An ensemble of these architectures further enhanced robustness and generalization.",
    "thumbnail": "./projects/sentiment-analysis-ablation-study.png",
    "technologies": [
      "Python",
      "TensorFlow",
      "PyTorch",
      "Keras",
      "NumPy",
      "pandas",
      "matplotlib"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4002-Sentiment-Analysis",
    "demo": "",
    "completed": "2024-11"
  },
  {
    "id": "image-segmentation-3d-stereo-vision",
    "title": "Image Segmentation & 3D Stereo Vision",
    "description": "A MATLAB lab project comparing document image segmentation techniques and stereo disparity methods for 3D reconstruction.",
    "longDescription": "This lab implements and evaluates multiple image segmentation techniques—Otsu’s global thresholding, Niblack’s local thresholding with Bayesian optimization, Sauvola’s adaptive thresholding, and Gabor filter feature extraction with K-Means clustering—to isolate text from degraded document images. It also explores 3D stereo vision by computing disparity maps from stereo image pairs using SSD, NCC/ZNCC, and SAD similarity metrics to infer depth information.\n\nDeveloped entirely in MATLAB using the Image Processing Toolbox and Statistics and Machine Learning Toolbox, with Bayesian optimization for parameter tuning, the project generates quantitative and visual results for each method. All source scripts, image datasets, and a detailed report are included for reproducibility and further analysis.",
    "thumbnail": "./projects/image-segmentation-3d-stereo-vision.png",
    "technologies": [
        "MATLAB"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4061-Lab-2",
    "demo": "",
    "completed": "2024-11"
  },
  {
    "id": "point-processing-spatial-frequency-filtering",
    "title": "Point Processing, Spatial & Frequency Filtering",
    "description": "An exploration of essential image enhancement and restoration techniques in MATLAB, covering intensity transformations, spatial filtering with both linear and non-linear kernels, and noise reduction in the frequency domain.",
    "longDescription": "This lab demonstrates core image processing workflows in MATLAB, covering intensity transformations (contrast stretching, histogram equalization), spatial filtering (Gaussian and median), frequency-domain noise reduction, perspective correction, and basic classification techniques. Each method is evaluated on sample images to assess its impact on enhancement and restoration.",
    "thumbnail": "./projects/point-processing-spatial-frequency-filtering.png",
    "technologies": [
        "MATLAB"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4061-Lab-1",
    "demo": "",
    "completed": "2024-09"
  },
  {
    "id": "moblima",
    "title": "MOBLIMA: OOP Movie Booking System",
    "description": "An object-oriented cinema booking application with user authentication, age-based restrictions, dynamic ticket pricing, and administrative controls.",
    "longDescription": "MOBLIMA is a group project from the SC2002 Object-Oriented Design and Programming course, providing a full-featured movie booking system. End users can register, log in, browse available movies, and book tickets; the system enforces age restrictions based on movie ratings (PG, NC16, M18) and computes ticket prices dynamically according to format (2D, 3D, 4DX, IMAX), user profile (adult, student, senior), and time factors (weekday vs. weekend). Administrators have elevated privileges to manage movies, schedules, and pricing parameters.\n\nArchitected with SOLID principles, the application leverages Java’s object-oriented features to ensure maintainability and extensibility. Interfaces and classes adhere to the Single Responsibility, Open-Closed, and Interface Segregation principles; encapsulation and abstraction hide implementation details. A comprehensive UML class diagram and detailed JavaDoc accompany the code, and rigorous testing validates authentication, pricing logic, age enforcement, and admin operations.",
    "thumbnail": "./projects/moblima.png",
    "technologies": [
      "JavaScript",
      "HTML5",
      "CSS"
    ],
    "category": "Software Development",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC2002-MOBLIMA",
    "demo": "https://youtu.be/FUokMTk_E2I",
    "completed": "2022-11"
  },
  {
    "id": "cart-pole-dqn",
    "title": "Deep Q-Network Cart-Pole Balancing",
    "description": "A reinforcement learning agent implemented with TensorFlow that learns to balance a pole on a moving cart in the OpenAI Gym CartPole-v1 environment.",
    "longDescription": "This project applies deep reinforcement learning to the classic cart-pole control problem. A Deep Q-Network with two hidden layers is trained via an epsilon-greedy policy and experience replay to learn optimal balancing strategies through interaction with the OpenAI Gym environment. Training performance is visualized using reward curves over multiple episodes, and the trained agent’s behavior is demonstrated through video renderings, offering an end-to-end workflow from environment setup and model design to evaluation and visualization.",
    "thumbnail": "./projects/cart-pole-dqn.gif",
    "technologies": [
      "Python",
      "TensorFlow",
      "NumPy",
      "matplotlib",
      "Jupyter"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC3000-Pole-Balancing",
    "demo": "",
    "completed": "2023-04"
  },
  {
    "id": "network-traffic-analysis",
    "title": "Network Traffic Analyzer",
    "description": "A data-driven network traffic analysis tool that processes raw packet logs to reveal communication patterns, protocol distributions, geolocations, and potential security threats.",
    "longDescription": "This project analyzes network traffic logs to uncover insights into usage patterns, bottlenecks, and security anomalies. It identifies top talkers and listeners, breaks down transport and application protocols, visualizes traffic intensity over time, and maps network activity geospatially. It also flags suspicious behaviors—such as port scanning—to support proactive network defense.\n\nImplemented in Python within Jupyter Notebooks, the workflow leverages pandas and NumPy for data processing, Matplotlib and Folium for dynamic visualizations, scapy for packet parsing, and GeoPandas for geolocation mapping. The end-to-end pipeline—from raw log ingestion through interactive report generation—provides a comprehensive framework for network monitoring and optimization.",
    "thumbnail": "./projects/network-traffic-analysis.png",
    "technologies": [
      "Python",
      "Jupyter",
      "pandas",
      "NumPy",
      "matplotlib"
    ],
    "category": "Data Science",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC2008-Network-Traffic-Analysis",
    "demo": "",
    "completed": "2022-10"
  },
  {
    "id": "softuni-trivia",
    "title": "SoftUni Django Trivia Game",
    "description": "A Django-based web trivia game with user authentication, dynamic lifelines, and question management, built as a final exam project for SoftUni.",
    "longDescription": "Developed for SoftUni’s Django course exam in 2019, this web trivia application offers users an engaging platform to test their general knowledge. Players can register, log in, and progress through rounds of questions using helpful in-game aids—fifty-fifty, right answer, and answer removal—to enhance gameplay. Administrators can restart sessions to manage ongoing games.\n\nThe system features full CRUD operations for trivia questions with role-based access control, records and displays each user’s game history, and maintains a consistent UI/UX through shared templates and a CSS framework. Architected in modular Django apps (accounts, game, games, questions, common) and backed by SQLite, it demonstrates best practices in web application design and deployment.",
    "thumbnail": "./projects/softuni-trivia.png",
    "technologies": [
      "Python",
      "Django",
      "SQLite",
      "HTML5",
      "CSS"
    ],
    "category": "Software Development",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SoftUni-Trivia",
    "demo": "",
    "completed": "2019-06"
  },
  {
    "id": "sql-query-evolution-analyzer",
    "title": "SQL Query Evolution Analyzer",
    "description": "A user-friendly tool for comparing SQL queries by visualizing execution plan differences and generating plain-English explanations to aid optimization.",
    "longDescription": "This application streamlines query optimization for users of all skill levels by generating and displaying Query Execution Plans (QEPs) for both original and modified SQL statements, automatically detecting and highlighting structural and cost-related differences, and offering clear, natural-language summaries of the changes. It features a modern, dark-themed GUI built with Tkinter and CustomTkinter, with Graphviz-powered plan diagrams and a history manager for saving and recalling past analyses. The tool connects to PostgreSQL via psycopg2, parses and validates SQL with sqlparse and sqlvalidator, and adapts its appearance to the system theme using Darkdetect.",
    "thumbnail": "./projects/sql-query-evolution-analyzer.png",
    "technologies": [
      "Python"
    ],
    "category": "Data Science",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC3020-Query-Analyzer",
    "demo": "",
    "completed": "2023-04"
  },
  {
    "id": "market-basket-analysis",
    "title": "Market Basket Analysis for E-commerce",
    "description": "A market-basket analysis project identifying product affinities and recommending complementary items to boost sales, with additional insights into customer segments and inventory.",
    "longDescription": "This project conducts association rule mining on transaction data from an e-commerce store to discover frequently co-purchased items and generate targeted product recommendations. Through thorough exploratory data analysis, frequent itemsets and high-confidence rules are extracted to inform cross-selling strategies. Further analysis on customer segmentation and inventory utilization provides actionable insights for marketing optimization and stock management.",
    "thumbnail": "./projects/market-basket-analysis.png",
    "technologies": [
      "Python",
      "Jupyter",
      "pandas",
      "NumPy",
      "matplotlib",
      "seaborn"
    ],
    "category": "Data Science",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC1015-Market-Basket-Analysis",
    "demo": "",
    "completed": "2022-04"
  },
  {
    "id": "speech-analysis-housing-prediction",
    "title": "Neural Networks: Speech Polarity & Housing Price Prediction",
    "description": "A dual-stage deep learning assignment combining speech polarity classification and HDB flat resale price regression.",
    "longDescription": "This project showcases two complementary neural network applications. In the first stage, a feedforward network is trained on extracted audio features to detect speech polarity, with thorough hyperparameter tuning via cross-validation and interpretation of predictions using SHAP. In the second stage, advanced PyTorch architectures (PyTorch Tabular and Pytorch-WideDeep) are employed to predict HDB flat resale prices, with model explainability using Captum and drift analysis via Alibi Detect.\n\nBuilt in Python within Jupyter Notebooks, the end-to-end workflow covers data preprocessing, model design, training, evaluation (accuracy for classification; RMSE and R² for regression), and visualizations of learning curves and prediction outcomes. This assignment illustrates best practices in deep learning experimentation, model robustness, and interpretability across both audio and tabular domains.",
    "thumbnail": "./projects/speech-analysis-housing-prediction.png",
    "technologies": [
      "Python",
      "Jupyter",
      "NumPy",
      "pandas",
      "matplotlib",
      "seaborn",
      "scikit-learn",
      "PyTorch"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4001-Speech-Analysis-and-Housing-Prediction",
    "demo": "",
    "completed": "2024-03"
  },
  {
    "id": "agent-decision-making",
    "title": "Maze Solver Agent with Value and Policy Iteration",
    "description": "An implementation of value and policy iteration algorithms that computes optimal policies and utilities in a grid-based maze environment.",
    "longDescription": "This project develops an intelligent agent for solving maze environments using Markov Decision Process techniques. It implements both value iteration and policy iteration to compute state utilities and derive optimal action policies for each non-wall state. The workflow includes visualizing convergence of utility and policy through reward and utility plots, rendering the maze with annotated optimal moves, and automated tests to verify algorithm correctness and performance.",
    "thumbnail": "./projects/agent-decision-making.png",
    "technologies": [
      "Python",
      "NumPy",
      "matplotlib"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4003-Agent-Decision-Making",
    "demo": "",
    "completed": "2024-03"
  },
  {
    "id": "speech-emotion-recognition",
    "title": "Multimodal Speech & Text Emotion Recognition",
    "description": "A multimodal emotion recognition system that integrates speech-to-text conversion and deep learning classifiers to detect emotional states from audio and text data.",
    "longDescription": "This project explores multimodal emotion recognition by combining speech-based and text-based analysis. Speech inputs are transcribed with OpenAI’s Whisper model, acoustic features are extracted using Librosa and openSMILE, and a Multi-Layer Perceptron classifies audio emotion. In parallel, a Convolutional Neural Network processes textual inputs. A fusion model then dynamically integrates both modalities to deliver context-aware emotion predictions.\n\nDeveloped in Python within Jupyter Notebooks, the workflow covers data preprocessing, model training, and hyperparameter tuning. Multiple CNN variants (including GRU, Bi-GRU, and LSTM) and MLP architectures were benchmarked. The final fusion model achieved 71.87% validation accuracy, outperforming standalone text (60.04%) and audio (68.91%) classifiers. All experiments are reproducible via provided notebooks and PyTorch checkpoints.",
    "thumbnail": "./projects/speech-emotion-recognition.png",
    "technologies": [
      "Python",
      "Jupyter",
      "PyTorch",
      "TensorFlow"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4001-Speech-Emotion-Recognition",
    "demo": "",
    "completed": "2024-04"
  },
  {
    "id": "opinion-search-engine",
    "title": "Opinion Search Engine for VR/AR Headset Discussions",
    "description": "An NLP-powered search engine that retrieves and analyzes public opinions on VR and AR headsets from Reddit.",
    "longDescription": "The Opinion Search Engine (OSE) combines Reddit data crawling, advanced text processing, and an Apache Solr–based index to allow users to search VR and AR headset discussions with high relevance. It features phonetic encoding, synonym expansion, spell-checking, and ranking enhancements for precise query results.\n\nA modern web application built with Next.js, React, Tailwind CSS, and Material Tailwind, it visualizes sentiment distributions using Plotly.js. Machine-learning sentiment analysis employs an ensemble of fine-tuned RoBERTa models to classify discussion sentiment with high precision, recall, and F1 score.",
    "thumbnail": "./projects/opinion-search-engine.png",
    "technologies": [
      "Apache Solr",
      "Python",
      "pandas",
      "scikit-learn",
      "Next.js",
      "React",
      "Tailwind CSS",
      "Plotly"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4021-OSE",
    "demo": "https://youtu.be/P68TdXkUfHA",
    "completed": "2025-02"
  },
  {
    "id": "collaboration-network-analysis",
    "title": "Network Science Analysis of Data Scientists Collaboration",
    "description": "A network science-based study of DBLP collaboration data revealing structural properties, evolution, and reduction strategies in a large-scale scientist network.",
    "longDescription": "This project constructs and analyzes a large-scale collaboration network of data scientists extracted from DBLP, exploring degree distributions, clustering coefficients, centrality measures, and component structures. It compares the real network to an Erdős-Rényi random graph to highlight scale-free characteristics and studies network evolution over time, tracking hub emergence and connectivity changes.\n\nAdditionally, the project implements network reduction techniques—such as degree cutoff and closeness centrality scaling—to preserve key structural properties while decreasing network size. The workflow combines advanced data preprocessing, NetworkX-based analysis, and interactive visualizations to provide comprehensive insights into scientific collaborations.",
    "thumbnail": "./projects/collaboration-network-analysis.png",
    "technologies": [
      "Python",
      "Jupyter",
      "pandas",
      "NumPy",
      "matplotlib"
    ],
    "category": "Data Science",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4022-Collaboration-Network-Analysis",
    "demo": "",
    "completed": "2024-04"
  },
  {
    "id": "repeated-prisoners-dilemma-agent",
    "title": "Three-Player Repeated Prisoners’ Dilemma Agent",
    "description": "An adaptive hybrid-strategy agent for three-player repeated Prisoners’ Dilemma tournaments that balances cooperation and defection through dynamic history analysis.",
    "longDescription": "This project implements a competitive agent tailored for three-player repeated Prisoners’ Dilemma tournaments, leveraging a hybrid strategy that blends classic game theory tactics (like Tit-for-Tat and Grim Trigger) with real-time history analysis, cooperative initiation, adaptive endgame defection, and punitive response mechanisms. A custom tournament framework simulates matches of variable length (90–110 rounds), pits the agent against diverse opponent strategies, and gathers statistical performance metrics to demonstrate robustness and strategic depth.",
    "thumbnail": "./projects/repeated-prisoners-dilemma-agent.png",
    "technologies": [
      "Java"
    ],
    "category": "Artificial Intelligence",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4003-Repeated-Prisoners-Dilemma-Agent",
    "demo": "",
    "completed": "2024-03"
  },
  {
    "id": "elo-merchant-category-recommendation",
    "title": "ELO Merchant Category Recommendation",
    "description": "A scalable machine-learning pipeline using dual LightGBM models and outlier detection to predict customer loyalty scores in the Kaggle ELO Merchant Category Recommendation challenge.",
    "longDescription": "This project tackles the ELO Merchant Category Recommendation challenge by combining a novel dual-model strategy with extensive feature engineering. A binary LightGBM classifier first identifies outlier transactions, and two separate LightGBM regressors—one trained on all data and another on non-outliers—produce loyalty score predictions depending on the classifier’s output. This targeted approach improves accuracy and robustness against anomalous records.\n\nThe end-to-end workflow, implemented in Jupyter Notebooks, includes exploratory data analysis, data cleaning, behavioral and interaction feature construction, automated feature selection, and systematic hyperparameter tuning via cross-validation. The final solution achieved a public leaderboard RMSE of 3.68232, placing in the top 6.7% of participants.",
    "thumbnail": "./projects/elo-merchant-category-recommendation.png",
    "technologies": [
      "Python",
      "Jupyter",
      "pandas",
      "NumPy",
      "matplotlib"
    ],
    "category": "Data Science",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC4000-ELO-Merchant-Category-Recommendation",
    "demo": "",
    "completed": "2024-04"
  },
  {
    "id": "scse-buddy",
    "title": "SCSEBuddy: 360° Indoor Navigation & Community Forum",
    "description": "An Android app offering immersive 360° indoor navigation within NTU’s SCSE building and integrated community features like course reviews and discussion forums.",
    "longDescription": "SCSEBuddy provides SCSE students with an end-to-end 360° indoor navigation experience by leveraging panoramic imagery and Dijkstra’s algorithm to compute and display the shortest routes across multiple floors. Users input their current location and desired destination to receive a sequence of annotated panoramic views with directional markers and stair instructions, ensuring intuitive wayfinding even in complex building layouts.\n\nBeyond navigation, the app fosters campus engagement through built-in course review and forum modules, allowing students to share feedback, ask questions, and collaborate. Developed in Java with the Android SDK and managed via Gradle, SCSEBuddy is optimized for Android 10 (API level 29) or higher, delivering smooth performance and reliable routing on both devices and emulators.",
    "thumbnail": "./projects/scse-buddy.png",
    "technologies": [
      "Java"
    ],
    "category": "Software Development",
    "featured": false,
    "github": "https://github.com/KristiyanCholakov/SC2006-SCSE-Buddy",
    "demo": "https://youtu.be/If7BrzpTVg4",
    "completed": "2022-06"
  }
]